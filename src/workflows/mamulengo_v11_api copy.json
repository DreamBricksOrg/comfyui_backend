{
  "5": {
    "inputs": {
      "width": 960,
      "height": 1440,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "Empty Latent Image"
    }
  },
  "6": {
    "inputs": {
      "text": [
        "3065",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "3057",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "photo, realistic, realism, extralimb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation, extra limbs, deformed, low quality, watermark",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "3057",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "3000": {
    "inputs": {
      "lora_name": "mamulengo_03-000006.safetensors",
      "strength_model": 1.0000000000000002,
      "strength_clip": 0.9800000000000002,
      "model": [
        "3057",
        0
      ],
      "clip": [
        "3057",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "3001": {
    "inputs": {
      "image": "mamulengo_man_512px_v01.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3002": {
    "inputs": {
      "seed": 11,
      "steps": 30,
      "cfg": 1.5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.8000000000000002,
      "model": [
        "3000",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "3006",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "3003": {
    "inputs": {
      "samples": [
        "3002",
        0
      ],
      "vae": [
        "3057",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "3005": {
    "inputs": {
      "width": 960,
      "height": 0,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "3077",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "3006": {
    "inputs": {
      "pixels": [
        "3005",
        0
      ],
      "vae": [
        "3057",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "3023": {
    "inputs": {
      "image": "kingsday_in_f1c93247-83fa-4183-937a-14e1a9936f19_20250610_170911.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3031": {
    "inputs": {
      "text": [
        "3068",
        0
      ],
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "3057",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "3032": {
    "inputs": {
      "text": "blurry, noisy, messy, glitch, distorted, malformed, ill, horror, naked, nipples",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "clip": [
        "3057",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "3033": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "3057",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "3034": {
    "inputs": {
      "lora_name": "mamulengo_03-000006.safetensors",
      "strength_model": 0.9900000000000002,
      "strength_clip": 1.0000000000000002,
      "model": [
        "3049",
        0
      ],
      "clip": [
        "3057",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "3035": {
    "inputs": {
      "seed": 20,
      "steps": 30,
      "cfg": 1.8800000000000001,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 0.9800000000000002,
      "model": [
        "3034",
        0
      ],
      "positive": [
        "3039",
        0
      ],
      "negative": [
        "3039",
        1
      ],
      "latent_image": [
        "3036",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "3036": {
    "inputs": {
      "pixels": [
        "3037",
        0
      ],
      "vae": [
        "3057",
        2
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "3037": {
    "inputs": {
      "width": 960,
      "height": 0,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 0,
      "image": [
        "3092",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "3038": {
    "inputs": {
      "control_net_name": "diffusers_xl_depth_full.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "3039": {
    "inputs": {
      "strength": 1,
      "start_percent": 0,
      "end_percent": 0.3,
      "positive": [
        "3050",
        0
      ],
      "negative": [
        "3050",
        1
      ],
      "control_net": [
        "3038",
        0
      ],
      "image": [
        "3052",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "3040": {
    "inputs": {
      "filename_prefix": "out_mamulengo_",
      "images": [
        "3102",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "3042": {
    "inputs": {
      "area": "face+forehead (if available)",
      "grow": 0,
      "grow_tapered": false,
      "blur": 13,
      "analysis_models": [
        "3046",
        0
      ],
      "image": [
        "3071",
        0
      ]
    },
    "class_type": "FaceSegmentation",
    "_meta": {
      "title": "Face Segmentation"
    }
  },
  "3043": {
    "inputs": {
      "model": "Florence-2-base",
      "precision": "fp16",
      "attention": "sdpa",
      "convert_to_safetensors": false
    },
    "class_type": "Florence2ModelLoader",
    "_meta": {
      "title": "Florence2ModelLoader"
    }
  },
  "3044": {
    "inputs": {
      "text_input": "",
      "task": "more_detailed_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 281764972721968,
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "image": [
        "3042",
        3
      ],
      "florence2_model": [
        "3043",
        0
      ]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "3045": {
    "inputs": {
      "PreviewTextNode_2": "The image is a close-up portrait of a man's face. He appears to be in his late twenties or early thirties, with short dark hair and a mustache. He has a nose ring on his nose and is looking directly at the camera with a slight smile. He is wearing a blue jacket and has a serious expression on his face. The background is blurred, but it seems to be a room with shelves and other items visible.",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "text": [
        "3044",
        2
      ]
    },
    "class_type": "PreviewTextNode",
    "_meta": {
      "title": "Preview Text Node"
    }
  },
  "3046": {
    "inputs": {
      "library": "dlib",
      "provider": "CPU"
    },
    "class_type": "FaceAnalysisModels",
    "_meta": {
      "title": "Face Analysis Models"
    }
  },
  "3047": {
    "inputs": {
      "low_threshold": 0.07,
      "high_threshold": 0.31000000000000005,
      "image": [
        "3037",
        0
      ]
    },
    "class_type": "Canny",
    "_meta": {
      "title": "Canny"
    }
  },
  "3049": {
    "inputs": {
      "weight_style": 1,
      "weight_composition": 1,
      "expand_style": false,
      "combine_embeds": "average",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "3033",
        0
      ],
      "ipadapter": [
        "3033",
        1
      ],
      "image_style": [
        "3003",
        0
      ],
      "image_composition": [
        "3092",
        0
      ]
    },
    "class_type": "IPAdapterStyleComposition",
    "_meta": {
      "title": "IPAdapter Style & Composition SDXL"
    }
  },
  "3050": {
    "inputs": {
      "strength": 0.6200000000000001,
      "start_percent": 0,
      "end_percent": 0.75,
      "positive": [
        "3031",
        0
      ],
      "negative": [
        "3032",
        0
      ],
      "control_net": [
        "3051",
        0
      ],
      "image": [
        "3047",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "3051": {
    "inputs": {
      "control_net_name": "controlnetxlCNXL_saiCanny.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "3052": {
    "inputs": {
      "ckpt_name": "depth_anything_vitl14.pth",
      "resolution": 960,
      "image": [
        "3037",
        0
      ]
    },
    "class_type": "DepthAnythingPreprocessor",
    "_meta": {
      "title": "Depth Anything"
    }
  },
  "3054": {
    "inputs": {
      "samples": [
        "3035",
        0
      ],
      "vae": [
        "3057",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "3057": {
    "inputs": {
      "ckpt_name": "dreamshaperXL_v21TurboDPMSDE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "3063": {
    "inputs": {
      "string_a": "mamu13n60 stop motion character, stop motion character, animation, cartoon, disney, full body, neutral background\n\n",
      "string_b": [
        "3045",
        0
      ],
      "delimiter": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringConcatenate",
    "_meta": {
      "title": "Concatenate"
    }
  },
  "3064": {
    "inputs": {
      "PreviewTextNode_1": "mamu13n60 stop motion character, stop motion character, animation, cartoon, disney, full body, neutral background\n\nThe image is a close-up portrait of a man's face. He appears to be in his late twenties or early thirties, with short dark hair and a mustache. He has a nose ring on his nose and is looking directly at the camera with a slight smile. He is wearing a blue jacket and has a serious expression on his face. The background is blurred, but it seems to be a room with shelves and other items visible.\n\nclassic straw hat, colorful and festive",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "text": [
        "3065",
        0
      ]
    },
    "class_type": "PreviewTextNode",
    "_meta": {
      "title": "Preview Text Node"
    }
  },
  "3065": {
    "inputs": {
      "string_a": [
        "3063",
        0
      ],
      "string_b": "\n\nclassic straw hat, colorful and festive",
      "delimiter": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringConcatenate",
    "_meta": {
      "title": "Concatenate"
    }
  },
  "3067": {
    "inputs": {
      "string_a": "mamu13n60 stop motion character, open eyes\n\n",
      "string_b": [
        "3045",
        0
      ],
      "delimiter": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringConcatenate",
    "_meta": {
      "title": "Concatenate"
    }
  },
  "3068": {
    "inputs": {
      "string_a": [
        "3067",
        0
      ],
      "string_b": "\nA cute handmade rag doll in Brazilian Festa Junina style, plaid shirt with patches, straw hat, soft face fabric, button eyes, colorful and festive.\n\ndetailed, high quality",
      "delimiter": "",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringConcatenate",
    "_meta": {
      "title": "Concatenate"
    }
  },
  "3069": {
    "inputs": {
      "PreviewTextNode_0": "mamu13n60 stop motion character, open eyes\n\nThe image is a close-up portrait of a man's face. He appears to be in his late twenties or early thirties, with short dark hair and a mustache. He has a nose ring on his nose and is looking directly at the camera with a slight smile. He is wearing a blue jacket and has a serious expression on his face. The background is blurred, but it seems to be a room with shelves and other items visible.\nA cute handmade rag doll in Brazilian Festa Junina style, plaid shirt with patches, straw hat, soft face fabric, button eyes, colorful and festive.\n\ndetailed, high quality",
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      },
      "text": [
        "3068",
        0
      ]
    },
    "class_type": "PreviewTextNode",
    "_meta": {
      "title": "Preview Text Node"
    }
  },
  "3071": {
    "inputs": {
      "width": 960,
      "height": 0,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "downscale if bigger",
      "multiple_of": 0,
      "image": [
        "3023",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "3075": {
    "inputs": {
      "string": [
        "3044",
        2
      ],
      "substring": "woman",
      "case_sensitive": false,
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringContains",
    "_meta": {
      "title": "Contains"
    }
  },
  "3076": {
    "inputs": {
      "preview": "0",
      "source": [
        "3087",
        0
      ]
    },
    "class_type": "PreviewAny",
    "_meta": {
      "title": "Preview Any"
    }
  },
  "3077": {
    "inputs": {
      "evaluate": [
        "3087",
        0
      ],
      "on_true": [
        "3078",
        0
      ],
      "on_false": [
        "3001",
        0
      ]
    },
    "class_type": "SimpleCondition+",
    "_meta": {
      "title": "ðŸ”§ Simple Condition"
    }
  },
  "3078": {
    "inputs": {
      "image": "mamulengo_woman_512px_v01.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3082": {
    "inputs": {
      "string": [
        "3044",
        2
      ],
      "substring": "girl",
      "case_sensitive": false,
      "speak_and_recognation": {
        "__value__": [
          false,
          true
        ]
      }
    },
    "class_type": "StringContains",
    "_meta": {
      "title": "Contains"
    }
  },
  "3087": {
    "inputs": {
      "value": "a or b",
      "a": [
        "3075",
        0
      ],
      "b": [
        "3082",
        0
      ]
    },
    "class_type": "SimpleMath+",
    "_meta": {
      "title": "ðŸ”§ Simple Math"
    }
  },
  "3088": {
    "inputs": {
      "control_net_name": "instantid-controlnet.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "3089": {
    "inputs": {
      "image": "clipspace/clipspace-mask-5510476.3.png [input]"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3092": {
    "inputs": {
      "samples": [
        "3094",
        0
      ],
      "vae": [
        "3057",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "3094": {
    "inputs": {
      "seed": 610771838939965,
      "steps": 30,
      "cfg": 1.6,
      "sampler_name": "ddpm",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "3096",
        0
      ],
      "positive": [
        "3096",
        1
      ],
      "negative": [
        "3096",
        2
      ],
      "latent_image": [
        "3096",
        3
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "3096": {
    "inputs": {
      "instantid_file": "instantid-ip-adapter.bin",
      "insightface": "CPU",
      "weight": 0.9000000000000001,
      "start_at": 0,
      "end_at": 1,
      "blur_kernel": 51,
      "control_net": [
        "3088",
        0
      ],
      "model": [
        "3057",
        0
      ],
      "clip": [
        "3057",
        1
      ],
      "vae": [
        "3057",
        2
      ],
      "image_source": [
        "3097",
        0
      ],
      "image_face": [
        "3071",
        0
      ],
      "mask": [
        "3098",
        0
      ]
    },
    "class_type": "ApplyZenID",
    "_meta": {
      "title": "ZenID FaceSwap"
    }
  },
  "3097": {
    "inputs": {
      "evaluate": [
        "3087",
        0
      ],
      "on_true": [
        "3099",
        0
      ],
      "on_false": [
        "3089",
        0
      ]
    },
    "class_type": "SimpleCondition+",
    "_meta": {
      "title": "ðŸ”§ Simple Condition"
    }
  },
  "3098": {
    "inputs": {
      "evaluate": [
        "3087",
        0
      ],
      "on_true": [
        "3099",
        1
      ],
      "on_false": [
        "3089",
        1
      ]
    },
    "class_type": "SimpleCondition+",
    "_meta": {
      "title": "ðŸ”§ Simple Condition"
    }
  },
  "3099": {
    "inputs": {
      "image": "clipspace/clipspace-mask-5583232.4.png [input]"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3101": {
    "inputs": {
      "image": "mamulengo_frame_1080px_v01.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "3102": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": true,
      "destination": [
        "3101",
        0
      ],
      "source": [
        "3054",
        0
      ],
      "mask": [
        "3101",
        1
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  }
}